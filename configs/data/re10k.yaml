target: ldm.data.datamodule.DataModuleFromConfig

# Default params used.
image_size: 512
scenes: null
val_scenes: null
stride: 3
flip_trajectories: False
n_future: 1
n_ctxt: 1
normalize_flow: True

params:
  batch_size: 16
  num_workers: 16
  num_val_workers: 0 # Avoid a weird val dataloader issue
  shuffle_val_dataloader: True
  collate_fn: ldm.data.datamodule.collate_fn_diffmap

  train: #params train dataset
    target: ldm.data.re10k.Re10kDiffmapDataset
    params:
      root_dir: datasets/re10k
      scenes: ${data.scenes}
      val_scenes: ${data.val_scenes}
      stride: ${data.stride}
      n_future: ${data.n_future}
      n_ctxt: ${data.n_ctxt}
      flip_trajectories: ${data.flip_trajectories}
      normalize_flow: ${data.normalize_flow}
      image_transforms:
      - target: torchvision.transforms.Resize
        params:
          size: ${data.image_size}  #train img resolution
          interpolation: 3
      - target: torchvision.transforms.CenterCrop
        params:
          size: ${data.image_size}
      split: train
      

  validation: #params val dataset
    target: ldm.data.re10k.Re10kDiffmapDataset
    params: 
      root_dir: datasets/re10k
      scenes: ${data.scenes}
      val_scenes: ${data.val_scenes}
      stride: ${data.stride}
      n_future: ${data.n_future}
      n_ctxt: ${data.n_ctxt}
      flip_trajectories: ${data.flip_trajectories}
      normalize_flow: ${data.normalize_flow}
      image_transforms:
      - target: torchvision.transforms.Resize
        params:
          size: ${data.image_size}  #train img resolution
          interpolation: 3
      - target: torchvision.transforms.CenterCrop
        params:
          size: ${data.image_size}
      split: validation
  
  test: null